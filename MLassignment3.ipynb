{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d265fced-45a7-4101-8162-031c677db33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de469d72-ace6-4b74-91c9-e5c94b92f2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.45857</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.80050</td>\n",
       "      <td>1.059034e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.64245</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.07217</td>\n",
       "      <td>1.505891e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.06718</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.15940</td>\n",
       "      <td>1.058988e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.24005</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.24283</td>\n",
       "      <td>1.260617e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.19723</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.10947</td>\n",
       "      <td>6.309435e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>60567.94414</td>\n",
       "      <td>7.830362</td>\n",
       "      <td>6.137356</td>\n",
       "      <td>3.46</td>\n",
       "      <td>22837.36103</td>\n",
       "      <td>1.060194e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>78491.27543</td>\n",
       "      <td>6.999135</td>\n",
       "      <td>6.576763</td>\n",
       "      <td>4.02</td>\n",
       "      <td>25616.11549</td>\n",
       "      <td>1.482618e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>63390.68689</td>\n",
       "      <td>7.250591</td>\n",
       "      <td>4.805081</td>\n",
       "      <td>2.13</td>\n",
       "      <td>33266.14549</td>\n",
       "      <td>1.030730e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>68001.33124</td>\n",
       "      <td>5.534388</td>\n",
       "      <td>7.130144</td>\n",
       "      <td>5.44</td>\n",
       "      <td>42625.62016</td>\n",
       "      <td>1.198657e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>65510.58180</td>\n",
       "      <td>5.992305</td>\n",
       "      <td>6.792336</td>\n",
       "      <td>4.07</td>\n",
       "      <td>46501.28380</td>\n",
       "      <td>1.298950e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0          79545.45857             5.682861                   7.009188   \n",
       "1          79248.64245             6.002900                   6.730821   \n",
       "2          61287.06718             5.865890                   8.512727   \n",
       "3          63345.24005             7.188236                   5.586729   \n",
       "4          59982.19723             5.040555                   7.839388   \n",
       "...                ...                  ...                        ...   \n",
       "4995       60567.94414             7.830362                   6.137356   \n",
       "4996       78491.27543             6.999135                   6.576763   \n",
       "4997       63390.68689             7.250591                   4.805081   \n",
       "4998       68001.33124             5.534388                   7.130144   \n",
       "4999       65510.58180             5.992305                   6.792336   \n",
       "\n",
       "      Avg. Area Number of Bedrooms  Area Population         Price  \n",
       "0                             4.09      23086.80050  1.059034e+06  \n",
       "1                             3.09      40173.07217  1.505891e+06  \n",
       "2                             5.13      36882.15940  1.058988e+06  \n",
       "3                             3.26      34310.24283  1.260617e+06  \n",
       "4                             4.23      26354.10947  6.309435e+05  \n",
       "...                            ...              ...           ...  \n",
       "4995                          3.46      22837.36103  1.060194e+06  \n",
       "4996                          4.02      25616.11549  1.482618e+06  \n",
       "4997                          2.13      33266.14549  1.030730e+06  \n",
       "4998                          5.44      42625.62016  1.198657e+06  \n",
       "4999                          4.07      46501.28380  1.298950e+06  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Parth\\Downloads\\datasets\\USA_Housing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96905f0f-d234-4474-8103-8dc2c2455ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Price\",axis=1).values\n",
    "Y = df[\"Price\"].values.reshape(-1,1)\n",
    "n, m = X.shape\n",
    "print(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3212c0f5-f021-4832-ac13-21f8eb9e8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "Train samples: 4000, Test samples: 1000\n",
      "R2 on test: 0.9160772178427468\n",
      "Beta on test: [[1229576.99256303]\n",
      " [ 231741.87665386]\n",
      " [ 163580.77656518]\n",
      " [ 120724.77138501]\n",
      " [   2992.44913605]\n",
      " [ 152235.90009854]]\n",
      "\n",
      "Fold 2:\n",
      "Train samples: 4000, Test samples: 1000\n",
      "R2 on test: 0.9143333969899391\n",
      "Beta on test: [[1230849.57086595]\n",
      " [ 228974.55047422]\n",
      " [ 165649.73061314]\n",
      " [ 121581.22259031]\n",
      " [   2092.96829553]\n",
      " [ 150487.30339964]]\n",
      "\n",
      "Fold 3:\n",
      "Train samples: 4000, Test samples: 1000\n",
      "R2 on test: 0.9117030618560986\n",
      "Beta on test: [[1232873.37426632]\n",
      " [ 230188.68965355]\n",
      " [ 163701.4186032 ]\n",
      " [ 120701.00765817]\n",
      " [   1252.46057779]\n",
      " [ 151647.34958184]]\n",
      "\n",
      "Fold 4:\n",
      "Train samples: 4000, Test samples: 1000\n",
      "R2 on test: 0.9183132603899509\n",
      "Beta on test: [[1234421.84913666]\n",
      " [ 228971.0275827 ]\n",
      " [ 163502.2605837 ]\n",
      " [ 121992.89112759]\n",
      " [   3058.69562741]\n",
      " [ 149274.71505081]]\n",
      "\n",
      "Fold 5:\n",
      "Train samples: 4000, Test samples: 1000\n",
      "R2 on test: 0.924478954973583\n",
      "Beta on test: [[1.23264148e+06]\n",
      " [2.29893924e+05]\n",
      " [1.64575094e+05]\n",
      " [1.21797211e+05]\n",
      " [7.86135883e+02]\n",
      " [1.50562056e+05]]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state=42)\n",
    "\n",
    "best_beta = None\n",
    "best_r2 = -np.inf\n",
    "\n",
    "beta_values = []\n",
    "pred_values = []\n",
    "r2_values = []\n",
    "scaler_values = []\n",
    "\n",
    "def add_intercept(X):\n",
    "    n = X.shape[0]\n",
    "    return np.hstack([np.ones((n, 1)), X]) \n",
    "    \n",
    "for i,(train_idx,test_idx) in enumerate(kf.split(X),start=1):\n",
    "    X_train = X[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    Y_train = Y[train_idx]\n",
    "    Y_test = Y[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    # print(X_train_scaled)    \n",
    "\n",
    "    X_train_int = add_intercept(X_train_scaled)\n",
    "    X_test_int = add_intercept(X_test_scaled)\n",
    "\n",
    "    beta = np.linalg.pinv(X_train_int) @ Y_train\n",
    "    Y_pred = X_test_int @ beta\n",
    "\n",
    "    r2 = r2_score(Y_test,Y_pred)\n",
    "\n",
    "    beta_values.append(beta)\n",
    "    pred_values.append(Y_pred)\n",
    "    r2_values.append(r2)\n",
    "    scaler_values.append(scaler)\n",
    "    \n",
    "    print(f\"\\nFold {i}:\")\n",
    "    print(f\"Train samples: {len(train_idx)}, Test samples: {len(test_idx)}\")\n",
    "    print(f\"R2 on test: {r2}\")\n",
    "    print(f\"Beta on test: {beta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a981082-c891-4fe7-a909-15dabbc5f712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fold: fold 5 with R2 = 0.924479\n",
      "Best beta: [[1.23264148e+06]\n",
      " [2.29893924e+05]\n",
      " [1.64575094e+05]\n",
      " [1.21797211e+05]\n",
      " [7.86135883e+02]\n",
      " [1.50562056e+05]]\n"
     ]
    }
   ],
   "source": [
    "best_fold_idx = int(np.argmax(r2_values))\n",
    "best_beta = beta_values[best_fold_idx]\n",
    "best_scaler = scaler_values[best_fold_idx]\n",
    "print(f\"Best fold: fold {best_fold_idx+1} with R2 = {r2_values[best_fold_idx]:.6f}\")\n",
    "print(f\"Best beta: {beta_values[best_fold_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c473864f-923c-4469-a0af-ba6e4f477e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of best fold's beta on a 70/30 split (using best fold's scaler):\n",
      "R2 on 70% (train) using best_beta: 0.9169451291393231\n",
      "R2 on 30% (test)  using best_beta: 0.919309110301187\n"
     ]
    }
   ],
   "source": [
    "X_train70, X_test30, y_train70, y_test30 = train_test_split(\n",
    "    X, Y, test_size=0.30, random_state=123\n",
    ")\n",
    "\n",
    "X_train70_scaled = best_scaler.transform(X_train70)\n",
    "X_test30_scaled = best_scaler.transform(X_test30)\n",
    "\n",
    "X_train70_int = add_intercept(X_train70_scaled)\n",
    "X_test30_int  = add_intercept(X_test30_scaled)\n",
    "\n",
    "y_train70_pred = X_train70_int @ best_beta\n",
    "y_test30_pred = X_test30_int @ best_beta\n",
    "\n",
    "r2_train70 = r2_score(y_train70,y_train70_pred)\n",
    "r2_test30 = r2_score(y_test30,y_test30_pred)\n",
    "\n",
    "print(\"Evaluation of best fold's beta on a 70/30 split (using best fold's scaler):\")\n",
    "print(f\"R2 on 70% (train) using best_beta: {r2_train70}\")\n",
    "print(f\"R2 on 30% (test)  using best_beta: {r2_test30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02bb454f-bfa6-4409-8c22-6d47dc412381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(X):\n",
    "    return np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1.0 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "def gradient_descent(X, y, lr=0.01, n_iters=1000, verbose=False):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)  # initialize\n",
    "    losses = []\n",
    "    for it in range(n_iters):\n",
    "        preds = X.dot(theta)\n",
    "        error = preds - y\n",
    "        loss = (1/(2*m)) * np.sum(error**2)\n",
    "        losses.append(loss)\n",
    "        grad = (1/m) * X.T.dot(error)   # shape (n,)\n",
    "        theta -= lr * grad\n",
    "\n",
    "        # Divergence safety: if loss explodes, stop early\n",
    "        if np.isnan(loss) or np.isinf(loss) or loss > 1e20:\n",
    "            if verbose:\n",
    "                print(f\"Stopped early at iter {it} due to divergence (loss={loss}).\")\n",
    "            break\n",
    "    return theta, losses\n",
    "\n",
    "def run_experiment(\n",
    "    X, y,\n",
    "    test_size=0.30, val_size=0.14,\n",
    "    learning_rates=[0.001, 0.01, 0.1, 1],\n",
    "    n_iters=1000,\n",
    "    random_state=42,\n",
    "    stratify=None  # set to y for classification-like stratify (if applicable)\n",
    "):\n",
    "    # 1) Split dataset into train/val/test (56/14/30)\n",
    "    # We'll first split off test (30%), then split remaining 70% into 80/20 -> 56/14\n",
    "    X_rem, X_test, y_rem, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=True, stratify=stratify\n",
    "    )\n",
    "    # proportion of val relative to remaining: val_size / (1 - test_size)\n",
    "    rel_val_size = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_rem, y_rem, test_size=rel_val_size, random_state=random_state, shuffle=True,\n",
    "        stratify=(y_rem if stratify is not None else None)\n",
    "    )\n",
    "\n",
    "    # 2) Feature scaling (fit on train only)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled   = scaler.transform(X_val)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    # Add bias\n",
    "    X_train_b = add_bias(X_train_scaled)\n",
    "    X_val_b   = add_bias(X_val_scaled)\n",
    "    X_test_b  = add_bias(X_test_scaled)\n",
    "\n",
    "    results = []\n",
    "    for lr in learning_rates:\n",
    "        theta, losses = gradient_descent(X_train_b, y_train, lr=lr, n_iters=n_iters)\n",
    "        # Predictions\n",
    "        y_val_pred = X_val_b.dot(theta)\n",
    "        y_test_pred = X_test_b.dot(theta)\n",
    "        r2_val = r2_score(y_val, y_val_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        results.append({\n",
    "            'lr': lr,\n",
    "            'theta': theta,\n",
    "            'loss_history': losses,\n",
    "            'final_train_loss': losses[-1] if len(losses)>0 else None,\n",
    "            'r2_val': r2_val,\n",
    "            'r2_test': r2_test,\n",
    "            'diverged': (len(losses) < n_iters)\n",
    "        })\n",
    "        print(f\"lr={lr:>6} | val_R2={r2_val: .6f} | test_R2={r2_test: .6f} | final_loss={losses[-1]:.6e} | diverged={results[-1]['diverged']}\")\n",
    "\n",
    "    # Choose best by validation R^2 (higher is better)\n",
    "    best = max(results, key=lambda r: r['r2_val'])\n",
    "    print(\"\\nBest model (by validation R²):\")\n",
    "    print(f\"  lr = {best['lr']}\")\n",
    "    print(f\"  val R² = {best['r2_val']:.6f}\")\n",
    "    print(f\"  test R² = {best['r2_test']:.6f}\")\n",
    "    print(f\"  theta (bias first) = {best['theta']}\")\n",
    "    return {\n",
    "        'results': results,\n",
    "        'best': best,\n",
    "        'splits': {\n",
    "            'X_train': X_train, 'X_val': X_val, 'X_test': X_test,\n",
    "            'y_train': y_train, 'y_val': y_val, 'y_test': y_test\n",
    "        },\n",
    "        'scaler': scaler\n",
    "    }\n",
    "\n",
    "  \n",
    "# best = res['best']\n",
    "# plt.plot(best['loss_history'])\n",
    "# plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"Train loss (1/(2m) sum_sq)\")\n",
    "# plt.title(f\"Loss history (lr={best['lr']})\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45cf5f6e-a7fd-4289-84dd-376e76151aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr= 0.001 | val_R2=-0.800529 | test_R2=-0.987306 | final_loss=1.160438e+11 | diverged=False\n",
      "lr=  0.01 | val_R2= 0.909850 | test_R2= 0.914744 | final_loss=5.037731e+09 | diverged=False\n",
      "lr=   0.1 | val_R2= 0.909831 | test_R2= 0.914757 | final_loss=5.037687e+09 | diverged=False\n",
      "lr=     1 | val_R2= 0.909831 | test_R2= 0.914757 | final_loss=5.037687e+09 | diverged=False\n",
      "\n",
      "Best model (by validation R²):\n",
      "  lr = 0.01\n",
      "  val R² = 0.909850\n",
      "  test R² = 0.914744\n",
      "  theta (bias first) = [1232451.13728891  234580.02202884  162424.51400554  121501.08421757\n",
      "    3090.26111211  151605.17031522]\n"
     ]
    }
   ],
   "source": [
    "feature_cols=[\"Avg. Area Income\",\"Avg. Area House Age\",\"Avg. Area Number of Rooms\",\"Avg. Area Number of Bedrooms\",\"Area Population\"]\n",
    "target_col=[\"Price\"]\n",
    "X_all = df[feature_cols].values\n",
    "y_all = df[target_col].values.squeeze()\n",
    "\n",
    "res = run_experiment(X_all, y_all, learning_rates=[0.001,0.01,0.1,1], n_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11118b2-e0b3-4455-a7c0-abdfb715ac1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
